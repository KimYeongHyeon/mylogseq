- Paper
	- 저자: Kim
	- 날짜:
	- 상태: On
	- 주소: [논문](https://arxiv.org/abs/2111.15664), [코드](https://github.com/clovaai/donut)
	-
	- ## 데이터 샘플 [링크](https://github.com/clovaai/donut#data)
		- #### For Document Information Extraction
			- https://huggingface.co/datasets/naver-clova-ix/cord-v2
		-
	-
	- ## Introduction
		- `donut`  interprets all tasks as a JSON prediction problem.
		- Understanding document images (e.g., invoices) is a core but challenging task since it requires complex functions such as reading text and a holistic understanding of the document.
		- VDU는 document classification, information extraction, visual question anwering등의 응용 분야에 적용 가능
		- 일반적은 VDU 방법은 two-stage manner로 나눠 푼다.
			- 1) 문서 이미지에서 글자 읽기
			- 2) 문서를 깜짝 놀랄 정도로 이해하기
			- 대부분 딥러닝 기반의 OCR에 의존해 1)를 해결
			- ![image.png](../assets/image_1669701171135_0.png)
		- OCR 기반의 visual document understanding의 경우 다음과 같은 문제를 겪는다
			- OCR를 사용하는데 있어 높은 computational cost
			- 문서 종류나 언어에 대한 inflexibility => poor generalization ability
			- OCR error가 연속해서 퍼져 나감 (OCR error propagation to the sub-sequent process)
		- OCR dependency로 발생하는 문제 해결을 위해 OCR-free VDU model 제안
		- Pre-train-and-fine-tune scheme을 따름
			- pre-training phase: 이미지와 이전 텍스트 문맥에 대한 조건부 확률로 다음 단어를 예측함으로써 **how to read the texts**
			- fine-tune phase: Downstream task에 맞게 **how to understand the whole document**
			- ![image.png](../assets/image_1669798011071_0.png)
		-
	- ## Related Works
		-
	- ## Methodologies
		- ![image.png](../assets/image_1669798076279_0.png)
		- OCR과 BERT의 비약적인 발전으로, 여러 OCR-dependent VUD모델들은 그 둘을 합쳤으며,
		- 더 좋은 성능을 달성하기 위해 OCR과 model pretrain을 위한
	- ## Experiments
		-
	- ## Results
		-